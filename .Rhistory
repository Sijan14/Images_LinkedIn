knitr::kable(cor)
centre <- function(var){
var - mean(var, na.rm = TRUE)
}
clean_data <- clean_data %>%
mutate(
across(c(Inherence_Bias, RavensProgressiveMatrix_sum, conserv, educ, Belief_in_Just_World), list(cent = centre))
)
clean_data
model <- lm(Ought_Score ~ Inherence_Bias_cent + RavensProgressiveMatrix_sum_cent + conserv_cent + educ_cent + Belief_in_Just_World_cent, data = clean_data)
lm.beta(model)
data_coded <- clean_data %>%
mutate(gender = if_else(gender == "1",1 ,0 ) )
model <- lm(Ought_Score ~ Inherence_Bias_cent + RavensProgressiveMatrix_sum_cent + conserv_cent + educ_cent + Belief_in_Just_World_cent + gender, data = data_coded)
lm.beta(model)
summary(model)
confint(model)
Conserv_recoded <- data_coded %>%
mutate(liberals = if_else(conserv < 4, 1, 0),
moderates = if_else(conserv > 3 & conserv < 7, 1, 0 ),
conservatives = if_else(conserv > 7 & conserv < 10, 1, 0 ))
model1 <- lm(Ought_Score ~ liberals + conservatives, data = Conserv_recoded)
summary(model1)
lm.beta(model1)
model2 <- lm(Ought_Score ~ liberals + moderates, data = Conserv_recoded)
summary(model2)
lm.beta(model2)
Conserv_recoded1 <- data_coded %>%
mutate(new_conserv1 = if_else(conserv < 4, "liberals",
if_else(conserv > 3 & conserv < 7,"moderates","conservatives")))
Conserv_recoded1$new_conserv1 = as_factor(Conserv_recoded1$new_conserv1)
contrast1 = c(1, 0, -1)
contrast2 = c(1, -1, 0)
contrasts(Conserv_recoded1$new_conserv1) = cbind(contrast1, contrast2)
contrasts(Conserv_recoded1$new_conserv1)
m_contrasts <- lm(Ought_Score ~ new_conserv1, data = Conserv_recoded1)
summary(m_contrasts)
setwd("~/Documents/MA in I:O Psychology/Quantitative & Statistical Methods/Midterm #2")
install.packages(magrittr)
library(tidyverse)
library(lm.beta)
library(rstatix)
library(magrittr)
library(tidyverse)
library(lm.beta)
library(rstatix)
library(tidyverse)
library(lm.beta)
library(rstatix)
mid_data <- read.csv("Tworek and Cimpian 2016 Study 1 - Tworek and Cimpian 2016 Study 1.csv")
clean_data <- mid_data %>%
filter(excluded == 0)
cor <- cor_test(clean_data, c(Ought_Score, Inherence_Bias, educ, RavensProgressiveMatrix_sum, conserv, Belief_in_Just_World))
knitr::kable(cor)
centre <- function(var){
var - mean(var, na.rm = TRUE)
}
clean_data <- clean_data %>%
mutate(
across(c(Inherence_Bias, RavensProgressiveMatrix_sum, conserv, educ, Belief_in_Just_World), list(cent = centre))
)
clean_data
model <- lm(Ought_Score ~ Inherence_Bias_cent + RavensProgressiveMatrix_sum_cent + conserv_cent + educ_cent + Belief_in_Just_World_cent, data = clean_data)
lm.beta(model)
data_coded <- clean_data %>%
mutate(gender = if_else(gender == "1",1 ,0 ) )
model <- lm(Ought_Score ~ Inherence_Bias_cent + RavensProgressiveMatrix_sum_cent + conserv_cent + educ_cent + Belief_in_Just_World_cent + gender, data = data_coded)
lm.beta(model)
summary(model)
confint(model)
Conserv_recoded <- data_coded %>%
mutate(liberals = if_else(conserv < 4, 1, 0),
moderates = if_else(conserv > 3 & conserv < 7, 1, 0 ),
conservatives = if_else(conserv > 7 & conserv < 10, 1, 0 ))
model1 <- lm(Ought_Score ~ liberals + conservatives, data = Conserv_recoded)
summary(model1)
lm.beta(model1)
model2 <- lm(Ought_Score ~ liberals + moderates, data = Conserv_recoded)
summary(model2)
lm.beta(model2)
Conserv_recoded1 <- data_coded %>%
mutate(new_conserv1 = if_else(conserv < 4, "liberals",
if_else(conserv > 3 & conserv < 7,"moderates","conservatives")))
Conserv_recoded1$new_conserv1 = as_factor(Conserv_recoded1$new_conserv1)
contrast1 = c(1, 0, -1)
contrast2 = c(1, -1, 0)
contrasts(Conserv_recoded1$new_conserv1) = cbind(contrast1, contrast2)
contrasts(Conserv_recoded1$new_conserv1)
m_contrasts <- lm(Ought_Score ~ new_conserv1, data = Conserv_recoded1)
summary(m_contrasts)
centre <- function(var){
var - mean(var, na.rm = TRUE)
}
clean_data <- clean_data %>%
mutate(
across(c(Inherence_Bias, RavensProgressiveMatrix_sum, conserv, educ, Belief_in_Just_World), list(cent = centre))
)
model <- lm(Ought_Score ~ Inherence_Bias_cent + RavensProgressiveMatrix_sum_cent + conserv_cent + educ_cent + Belief_in_Just_World_cent, data = clean_data)
lm.beta(model)
install.packages('tinytex')
tinytex::copy_tinytex()
install.packages('tinytex')
tinytex::copy_tinytex()
install.packages("tinytex")
library(tinytex)
install.packages('tinytex')
tinytex::install_tinytex()
library(tinytex)
install.packages('tinytex')
tinytex::install_tinytex()
library(tinytex)
library(tinytex)
library(tidyverse)
library(lm.beta)
library(rstatix)
zhang <- zhang %>% rename(
InterestTime1 = T1_Predicted_Interest_Composite,
InterestTime2 = T2_Actual_Interest_Composite
)
zhang <- read_csv("Zhang et al. 2014 Study 3 - Zhang et al. 2014 Study 3.csv")
zhang <- zhang %>% rename(
InterestTime1 = T1_Predicted_Interest_Composite,
InterestTime2 = T2_Actual_Interest_Composite
)
## Irizarry: Chapter 5 (The tidyverse)
library(tidyverse)
load(co2)
co2
ChickWeight
head(ChickWeight)
# 5.3 Manipulating Data Frames
library(dslabs)
data("murders")
View(murders)
View(murders)
murders <- mutate(murders, rate = total/population * 100000)
View(murders)
View(murders)
head(murders)
# Subsetting with Filters
filter(murders, rate <= 0.71)
# Selecting columns with select
murders_three_column <- select(murders, state, region, rate)
filter(murders_three_column, rate <= 0.71)
source("~/Documents/MA in I:O Psychology/Data Science for Social Scientists/Week 2/Programming basic practice.R", echo=TRUE)
library(dplyr)
library(dslabs)
data("murders")
library(dplyr)
library(dslabs)
data("murders")
View(murders)
View(murders)
murders <- mutate(murders, population_in_millions = population / 10^6)
murders <- mutate(murders, rate = total/population * 100000)
#Question 2
murders <- mutate(murders, rank = rank(rate))
head(murders)
#Question 3
select(murders, state, population) %>% head()
#Question 4
filter(murders, state == "New York")
filter(murders, state, rank <= 5)
filter(murders, rank <= 5)
filter(murders, rank <= 5, states)
filter(murders, rank <= 5, state)
#Question 5
no_florida = filter(murders, state != "Florida")
View(no_florida)
View(no_florida)
View(no_florida)
#Question 5
no_south = filter(murders, region != "South")
nrow(no_south)
51 -nrow(no_south)
#Question 6
murders_nw = filter(murders, region %n% c("Northeast", "West"))
#Question 6
murders_nw = filter(murders, region %in% c("Northeast", "West"))
#Question 7
my_states <- filter(murders, rate < 1 & region %in% c("Northeast", "West"))
View(my_states)
#Question 7
my_states <- filter(murders, rate < 1 & region == "Northeast", "West")
#Question 7
my_states <- filter(murders, rate < 1 & region == "Northeast" or "West")
#Question 7
my_states <- filter(murders, rate < 1 & region == "Northeast"/ "West")
#Question 7
my_states <- filter(murders, rate < 1 & region %in% c("Northeast", "West"))
#Question 1
my_states <- filter(murders, rate < 1 & region %in% c("Northeast", "West")) %>% select(state, rate, rank)
head(my_states)
#Question 2
data(murders)
my_states <- murders %>%
mutate(rate = total/population * 100000, rank = rank(rate)) %>%
filter(region %in% c("Northeast", "West") & rate < 1) %>%
select(state, rate, rank)
View(my_states)
library(NHANES)
# 5.9 Exercises
library(NHANES)
# 5.9 Exercises
install.packages("NHANES")
library(NHANES)
data(NHANES)
#Question 1
ref <- NHANES %>%
filter(AgeDecade == " 20-29") %>%
summarize(average = mean(BPSysAve), standard_deviation = sd(BPSysAve), na.rm = TRUE)
View(ref)
View(ref)
#Question 1
ref <- NHANES %>%
filter(AgeDecade == " 20-29") %>%
summarize(average = mean(BPSysAve), standard_deviation = sd(BPSysAve))
View(ref)
#Question 1
ref <- NHANES %>%
filter(AgeDecade == " 20-29" & BPSysAve != "NA") %>%
summarize(average = mean(BPSysAve), standard_deviation = sd(BPSysAve))
View(ref)
ref1 <- NHANES %>%
filter(AgeDecade == " 20-29") %>%
summarize(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE))
View(ref1)
#Question 2
ref_avg <- NHANES %>%
filter(AgeDecade == " 20-29") %>%
summarize(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE)) %>%
pull(average, standard_deviation)
#Question 2
ref_avg <- NHANES %>%
filter(AgeDecade == " 20-29") %>%
summarize(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE)) %>%
pull(average, standard_deviation) %>%
head(ref_avg)
#Question 2
ref_avg <- NHANES %>%
filter(AgeDecade == " 20-29") %>%
summarize(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE)) %>%
pull(average, standard_deviation) %>%
head()
#Question 2
ref_avg <- NHANES %>%
filter(AgeDecade == " 20-29") %>%
summarize(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE)) %>%
pull(average) %>%
head()
summarize(minimum = min(BPSysAve, na.rm = TRUE), maximum(BPSysAve, na.rm = TRUE)
pull(minimum)
summarize(minimum = min(BPSysAve, na.rm = TRUE), maximum= max(BPSysAve, na.rm = TRUE)
#Question 3
NHANES %>%
#Question 3
min_max <- NHANES %>%
filter(AgeDecade == " 20-29") %>%
summarize(minimum = min(BPSysAve, na.rm = TRUE), maximum= max(BPSysAve, na.rm = TRUE))
View(min_max)
View(min_max)
View(NHANES)
View(NHANES)
#Question 4
female <- NHANES %>%
filter(Gender == "female") %>%
group_by(AgeDecade) %>%
summarize(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE))
View(female)
#Question 5
male <- NHANES %>%
filter(Gender == "male") %>%
group_by(AgeDecade) %>%
summarize(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE))
View(male)
View(male)
#Question 6
Combined_gender <- NHANES %>%
group_by(AgeDecade, Gender) %>%
summarize(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE))
View(Combined_gender)
#Question 6
Combined_gender <- NHANES %>%
group_by(AgeDecade, Gender) %>%
summarize.group(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE))
view(Combined_gender)
#Question 7
middle_age_male <- NHANES %>%
filter(Gender == "male" & AgeDecade == " 40-49") %>%
group_by(Race1) %>%
arrange(BPSysAve)
View(middle_age_male)
group_by(Race1) %>%
arrange(BPSysAve)
#Question 7
middle_age_male <- NHANES %>%
filter(Gender == "male" & AgeDecade == " 40-49") %>%
select(Gender, Race1, BPSysAve) %>%
group_by(Race1) %>%
arrange(BPSysAve)
View(middle_age_male)
#Question 7
middle_age_male <- NHANES %>%
filter(Gender == "male" & AgeDecade == " 40-49") %>%
select(AgeDecade, Gender, Race1, BPSysAve) %>%
group_by(Race1) %>%
arrange(BPSysAve)
View(middle_age_male)
View(Combined_gender)
#Question 7
middle_age_male <- NHANES %>%
filter(Gender == "male" & AgeDecade == " 40-49") %>%
select(AgeDecade, Gender, Race1, BPSysAve) %>%
arrange(BPSysAve)
View(middle_age_male)
View(middle_age_male)
#Question 7
middle_age_male <- NHANES %>%
filter(Gender == "male" & AgeDecade == " 40-49") %>%
group_by(Race1) %>%
summarize(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE)) %>%
arrange(BPSysAve)
#Question 7
middle_age_male <- NHANES %>%
filter(Gender == "male" & AgeDecade == " 40-49") %>%
group_by(Race1) %>%
summarize(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE)) %>%
arrange(average)
View(middle_age_male)
View(middle_age_male)
## 5.10 Tibbles
murders
as_tibble(murders)
# 5.16 Exercises
data(murders)
head(murders)
#Question 2
murders_tibbles <- as_tibble(murders)
#Question 3
mureders %>%
group_by(region)
#Question 3
murders %>%
group_by(region)
#Question 4
murders %>%
log(population) %>%
mean() %>%
.$population
#Question 4
murders %>%
log(population) %>%
mean() %>%
.$murders
#Question 4
murders %>%
.$population %>%
log() %>%
mean() %>%
exp()
.$population
#Question 4
murders %>%
log(population) %>%
mean() %>%
exp() %>%
.$population
#Question 4
murders %>%
.$population %>%
log() %>%
mean() %>%
exp()
exp(population)
#Question 4
murders %>%
.$population %>%
log() %>%
mean() %>%
exp()
#Question 5
install.packages("purrr")
install.packages("purrr")
library(purrr)
library(purrr)
library(purrr)
#Question 5
install.packages("purrr", dep = TRUE)
install.packages("purrr", dep = TRUE)
library(purrr)
num <- map_df(n, s_n)
s_n(100)
s_n <- function(n){
x <- 1:n
data_frame(sum = sum(x))
}
num <- map_df(n, s_n)
s_n(100)
s_n(100)
s_n <- function(n){
x <- 1:n
map_df(sum = sum(x))
}
s_n(100)
knitr::opts_chunk$set(echo = TRUE)
#Please run the ILA_Data_Merge_Clean_Script and ILA_Data_Score_Sort_Script to ensure the most updated dataset
ILA_Cleaned_Dataset_Analysis <- read_sav("ILA_Cleaned_Scored_Dataset.sav")
knitr::opts_chunk$set(echo = TRUE)
library(psych)
library(plyr)
library(dplyr)
library(readr)
library(writexl)
library(haven)
library(careless)
library(tidyr)
library(purrr)
library(lubridate)
library(stringr)
ILA_Cleaned_Dataset_Analysis <- read_sav("ILA_Cleaned_Scored_Dataset.sav")
ILA_CorrPlot <- ILA_Cleaned_Dataset_Analysis %>%
select(RME_Mean, Yoni_affect1st, Yoni_affect2nd, Yoni_cog1st, Yoni_cog2nd, Yoni_phys1st, Yoni_phys2nd, MASC_Overall_Correct_Proportion, MASC_Overall_Under_Mentalizing_Proportion, MASC_Overall_Over_Mentalizing_Proportion, MASC_Overall_No_ToM_Proportion, MASC_Emotion_Correct_Proportion, MASC_Emotion_Under_Mentalizing_Proportion, MASC_Emotion_Over_Mentalizing_Proportion, MASC_Emotion_No_ToM_Proportion, MASC_Thoughts_Correct_Proportion, MASC_Thoughts_Under_Mentalizing_Proportion, MASC_Thoughts_Over_Mentalizing_Proportion, MASC_Thoughts_No_ToM_Proportion, MASC_Intentions_Correct_Proportion, MASC_Intentions_Under_Mentalizing_Proportion, MASC_Intentions_Over_Mentalizing_Proportion, MASC_Intentions_No_ToM_Proportion, DP_Ctl_Mean, DA_Ctl_Mean, DP_Exp_Mean, DA_Exp_Mean, Parolini_1_SL_Mean, Parolini_2_SL_Mean, Parolini_2_TL_Mean, SLQ_Altruistic_Calling_Mean, SLQ_Emotional_Healing_Mean, SLQ_Wisdom_Mean, SLQ_Persuasive_Mapping_Mean, SLQ_Org_Stewardship_Mean, SLS_S_Global_Mean, SLS_S_Empowerment_Mean, SLS_S_StB_Mean, SLS_S_Accountability_Mean, SLS_S_Forgiveness_Mean, SLS_S_Courage_Mean, SLS_S_Authenticity_Mean, SLS_S_Humility_Mean, SLS_S_Stewardship_Mean, Leadership_Experience) %>%
cor(use="complete.obs")
RME_SLS_Parolini <- ILA_Cleaned_Dataset_Analysis %>%
select(RME_Mean, SLS_S_Global_Mean, SLS_S_Empowerment_Mean, SLS_S_StB_Mean, SLS_S_Accountability_Mean,  SLS_S_Forgiveness_Mean, SLS_S_Courage_Mean, SLS_S_Authenticity_Mean, SLS_S_Humility_Mean, SLS_S_Stewardship_Mean, Parolini_1_SL_Mean, Parolini_2_SL_Mean, Parolini_2_TL_Mean)
corr_matrix1 <- cor(RME_SLS_Parolini, method = "pearson")
corr_matrix1
ggcorrplot(corr_matrix1, method = 'square',
type = 'lower',
colors = c("red", "white", "blue"))
corr_matrix1 <- cor(RME_SLS_Parolini, method = "pearson", na.rm = T)
corr_matrix1 <- cor(RME_SLS_Parolini, method = "pearson", na.rm = TRUE)
corr_matrix1 <- cor(RME_SLS_Parolini, method = "pearson")
corr_matrix1 <- cor(RME_SLS_Parolini, method = "pearson", use = "complete.obs")
corr_matrix1
#Please run the ILA_Data_Merge_Clean_Script and ILA_Data_Score_Sort_Script to ensure the most updated dataset
library(corrplot)
ggcorrplot(corr_matrix1, method = 'square',
type = 'lower',
colors = c("red", "white", "blue"))
#Please run the ILA_Data_Merge_Clean_Script and ILA_Data_Score_Sort_Script to ensure the most updated dataset
library(ggcorrplot)
#Please run the ILA_Data_Merge_Clean_Script and ILA_Data_Score_Sort_Script to ensure the most updated dataset
install.packages("ggcorrplot")
library(ggcorrplot)
ggcorrplot(corr_matrix1, method = 'square',
type = 'lower',
colors = c("red", "white", "blue"))
YONI_SLS_Parolini <- ILA_Cleaned_Dataset_Analysis %>%
select(Yoni_affect1st, Yoni_affect2nd, Yoni_cog1st, Yoni_cog2nd, Yoni_phys1st, Yoni_phys2nd, SLS_S_Global_Mean, SLS_S_Empowerment_Mean, SLS_S_StB_Mean, SLS_S_Accountability_Mean,  SLS_S_Forgiveness_Mean, SLS_S_Courage_Mean, SLS_S_Authenticity_Mean, SLS_S_Humility_Mean, SLS_S_Stewardship_Mean, Parolini_1_SL_Mean, Parolini_2_SL_Mean, Parolini_2_TL_Mean)
corr_matrix2 <- cor(YONI_SLS_Parolini, method = "pearson", use = "complete.obs")
corr_matrix2
ggcorrplot(corr_matrix2, method = 'square',
type = 'lower',
colors = c("red", "white", "blue"))
YONI_SLS_Parolini <- ILA_Cleaned_Dataset_Analysis %>%
select(Yoni_affect1st, Yoni_affect2nd, Yoni_cog1st, Yoni_cog2nd, Yoni_phys1st, Yoni_phys2nd, SLS_S_Global_Mean, SLS_S_Empowerment_Mean, SLS_S_StB_Mean, SLS_S_Accountability_Mean,  SLS_S_Forgiveness_Mean, SLS_S_Courage_Mean, SLS_S_Authenticity_Mean, SLS_S_Humility_Mean, SLS_S_Stewardship_Mean, Parolini_1_SL_Mean, Parolini_2_SL_Mean, Parolini_2_TL_Mean)
corr_matrix2 <- cor(YONI_SLS_Parolini, method = "pearson", use = "complete.obs")
corr_matrix2
ggcorrplot(corr_matrix2, method = 'square',
type = 'lower',
colors = c("red", "white", "blue"))
MASC_SLS_Parolini <- ILA_Cleaned_Dataset_Analysis %>%
select(MASC_Overall_Correct_Proportion, MASC_Overall_Under_Mentalizing_Proportion, MASC_Overall_Over_Mentalizing_Proportion, MASC_Overall_No_ToM_Proportion, MASC_Emotion_Correct_Proportion, MASC_Emotion_Under_Mentalizing_Proportion, MASC_Emotion_Over_Mentalizing_Proportion, MASC_Emotion_No_ToM_Proportion, MASC_Thoughts_Correct_Proportion, MASC_Thoughts_Under_Mentalizing_Proportion, MASC_Thoughts_Over_Mentalizing_Proportion, MASC_Thoughts_No_ToM_Proportion, MASC_Intentions_Correct_Proportion, MASC_Intentions_Under_Mentalizing_Proportion, MASC_Intentions_Over_Mentalizing_Proportion, MASC_Intentions_No_ToM_Proportion, SLS_S_Global_Mean, SLS_S_Empowerment_Mean, SLS_S_StB_Mean, SLS_S_Accountability_Mean,  SLS_S_Forgiveness_Mean, SLS_S_Courage_Mean, SLS_S_Authenticity_Mean, SLS_S_Humility_Mean, SLS_S_Stewardship_Mean, Parolini_1_SL_Mean, Parolini_2_SL_Mean, Parolini_2_TL_Mean)
corr_matrix3 <- cor(MASC_SLS_Parolini, method = "pearson", use = "complete.obs")
corr_matrix3
ggcorrplot(corr_matrix3, method = 'square',
type = 'lower',
colors = c("red", "white", "blue"))
MASC_SLS_Parolini <- ILA_Cleaned_Dataset_Analysis %>%
select(MASC_Overall_Correct_Proportion, MASC_Overall_Under_Mentalizing_Proportion, MASC_Overall_Over_Mentalizing_Proportion, MASC_Overall_No_ToM_Proportion, MASC_Emotion_Correct_Proportion, MASC_Emotion_Under_Mentalizing_Proportion, MASC_Emotion_Over_Mentalizing_Proportion, MASC_Emotion_No_ToM_Proportion, MASC_Thoughts_Correct_Proportion, MASC_Thoughts_Under_Mentalizing_Proportion, MASC_Thoughts_Over_Mentalizing_Proportion, MASC_Thoughts_No_ToM_Proportion, MASC_Intentions_Correct_Proportion, MASC_Intentions_Under_Mentalizing_Proportion, MASC_Intentions_Over_Mentalizing_Proportion, MASC_Intentions_No_ToM_Proportion, SLS_S_Global_Mean, SLS_S_Empowerment_Mean, SLS_S_StB_Mean, SLS_S_Accountability_Mean,  SLS_S_Forgiveness_Mean, SLS_S_Courage_Mean, SLS_S_Authenticity_Mean, SLS_S_Humility_Mean, SLS_S_Stewardship_Mean, Parolini_1_SL_Mean, Parolini_2_SL_Mean, Parolini_2_TL_Mean)
corr_matrix3 <- cor(MASC_SLS_Parolini, method = "pearson", use = "complete.obs")
corr_matrix3
ggcorrplot(corr_matrix3, method = 'square',
type = 'lower',
colors = c("red", "white", "blue"))
p + theme(text = element_text(size = 8),
axis.text.x = element_text(angle = 90, hjust = 1))
p <- ggcorrplot(corr_matrix3, method = 'square',
type = 'lower',
colors = c("red", "white", "blue"))
p + theme(text = element_text(size = 8),
axis.text.x = element_text(angle = 90, hjust = 1))
p + theme(text = element_text(size = 1),
axis.text.x = element_text(angle = 90, hjust = 1))
p + theme(text = element_text(size = 0.5),
axis.text.x = element_text(angle = 90, hjust = 1))
p + theme(text = element_text(size = 0.5),
axis.text.x = element_text(angle = 45, hjust = 1))
p + theme(text = element_text(size = 0.05),
axis.text.x = element_text(angle = 45, hjust = 1))
p + theme(text = element_text(size = 0.005),
axis.text.x = element_text(angle = 45, hjust = 1))
p + theme(text = element_text(size = 0.000005),
axis.text.x = element_text(angle = 45, hjust = 1))
p + theme(text = element_text(size = 0.000001),
axis.text.x = element_text(angle = 45, hjust = 1))
p + theme(axis.text.x = element_text(size = 1,angle = 45, hjust = 1))
p + theme(axis.text.Y = element_text(size = 8, hjust = 1),
axis.text.x = element_text(size = 1, angle = 45, hjust = 1))
p + theme(axis.text.Y = element_text(size = 8, hjust = 1),
axis.text.x = element_text(size = 1, angle = 45, hjust = 1))
p + theme(axis.text.y = element_text(size = 8, hjust = 1),
axis.text.x = element_text(size = 1, angle = 45, hjust = 1))
p + theme(axis.text.y = element_text(size = 8, hjust = 1),
axis.text.x = element_text(size = 8, angle = 45, hjust = 1))
p + theme(axis.text.y = element_text(size = 8, hjust = 1),
axis.text.x = element_text(size = 8, angle = 90, hjust = 1))
p + theme(axis.text.y = element_text(size = 7, hjust = 1),
axis.text.x = element_text(size = 7, angle = 90, hjust = 1))
getwd()
setwd("/Users/sijanikbal/Documents/Ph.D. in I:O Psychology/Research Labs/Research Lab with Dr. Salter/Images_LinkedIn")
