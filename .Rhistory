ref <- NHANES %>%
filter(AgeDecade == " 20-29" & BPSysAve != "NA") %>%
summarize(average = mean(BPSysAve), standard_deviation = sd(BPSysAve))
View(ref)
ref1 <- NHANES %>%
filter(AgeDecade == " 20-29") %>%
summarize(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE))
View(ref1)
#Question 2
ref_avg <- NHANES %>%
filter(AgeDecade == " 20-29") %>%
summarize(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE)) %>%
pull(average, standard_deviation)
#Question 2
ref_avg <- NHANES %>%
filter(AgeDecade == " 20-29") %>%
summarize(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE)) %>%
pull(average, standard_deviation) %>%
head(ref_avg)
#Question 2
ref_avg <- NHANES %>%
filter(AgeDecade == " 20-29") %>%
summarize(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE)) %>%
pull(average, standard_deviation) %>%
head()
#Question 2
ref_avg <- NHANES %>%
filter(AgeDecade == " 20-29") %>%
summarize(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE)) %>%
pull(average) %>%
head()
summarize(minimum = min(BPSysAve, na.rm = TRUE), maximum(BPSysAve, na.rm = TRUE)
pull(minimum)
summarize(minimum = min(BPSysAve, na.rm = TRUE), maximum= max(BPSysAve, na.rm = TRUE)
#Question 3
NHANES %>%
#Question 3
min_max <- NHANES %>%
filter(AgeDecade == " 20-29") %>%
summarize(minimum = min(BPSysAve, na.rm = TRUE), maximum= max(BPSysAve, na.rm = TRUE))
View(min_max)
View(min_max)
View(NHANES)
View(NHANES)
#Question 4
female <- NHANES %>%
filter(Gender == "female") %>%
group_by(AgeDecade) %>%
summarize(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE))
View(female)
#Question 5
male <- NHANES %>%
filter(Gender == "male") %>%
group_by(AgeDecade) %>%
summarize(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE))
View(male)
View(male)
#Question 6
Combined_gender <- NHANES %>%
group_by(AgeDecade, Gender) %>%
summarize(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE))
View(Combined_gender)
#Question 6
Combined_gender <- NHANES %>%
group_by(AgeDecade, Gender) %>%
summarize.group(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE))
view(Combined_gender)
#Question 7
middle_age_male <- NHANES %>%
filter(Gender == "male" & AgeDecade == " 40-49") %>%
group_by(Race1) %>%
arrange(BPSysAve)
View(middle_age_male)
group_by(Race1) %>%
arrange(BPSysAve)
#Question 7
middle_age_male <- NHANES %>%
filter(Gender == "male" & AgeDecade == " 40-49") %>%
select(Gender, Race1, BPSysAve) %>%
group_by(Race1) %>%
arrange(BPSysAve)
View(middle_age_male)
#Question 7
middle_age_male <- NHANES %>%
filter(Gender == "male" & AgeDecade == " 40-49") %>%
select(AgeDecade, Gender, Race1, BPSysAve) %>%
group_by(Race1) %>%
arrange(BPSysAve)
View(middle_age_male)
View(Combined_gender)
#Question 7
middle_age_male <- NHANES %>%
filter(Gender == "male" & AgeDecade == " 40-49") %>%
select(AgeDecade, Gender, Race1, BPSysAve) %>%
arrange(BPSysAve)
View(middle_age_male)
View(middle_age_male)
#Question 7
middle_age_male <- NHANES %>%
filter(Gender == "male" & AgeDecade == " 40-49") %>%
group_by(Race1) %>%
summarize(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE)) %>%
arrange(BPSysAve)
#Question 7
middle_age_male <- NHANES %>%
filter(Gender == "male" & AgeDecade == " 40-49") %>%
group_by(Race1) %>%
summarize(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE)) %>%
arrange(average)
View(middle_age_male)
View(middle_age_male)
## 5.10 Tibbles
murders
as_tibble(murders)
# 5.16 Exercises
data(murders)
head(murders)
#Question 2
murders_tibbles <- as_tibble(murders)
#Question 3
mureders %>%
group_by(region)
#Question 3
murders %>%
group_by(region)
#Question 4
murders %>%
log(population) %>%
mean() %>%
.$population
#Question 4
murders %>%
log(population) %>%
mean() %>%
.$murders
#Question 4
murders %>%
.$population %>%
log() %>%
mean() %>%
exp()
.$population
#Question 4
murders %>%
log(population) %>%
mean() %>%
exp() %>%
.$population
#Question 4
murders %>%
.$population %>%
log() %>%
mean() %>%
exp()
exp(population)
#Question 4
murders %>%
.$population %>%
log() %>%
mean() %>%
exp()
#Question 5
install.packages("purrr")
install.packages("purrr")
library(purrr)
library(purrr)
library(purrr)
#Question 5
install.packages("purrr", dep = TRUE)
install.packages("purrr", dep = TRUE)
library(purrr)
num <- map_df(n, s_n)
s_n(100)
s_n <- function(n){
x <- 1:n
data_frame(sum = sum(x))
}
num <- map_df(n, s_n)
s_n(100)
s_n(100)
s_n <- function(n){
x <- 1:n
map_df(sum = sum(x))
}
s_n(100)
knitr::opts_chunk$set(echo = TRUE)
#Please run the ILA_Data_Merge_Clean_Script and ILA_Data_Score_Sort_Script to ensure the most updated dataset
ILA_Cleaned_Dataset_Analysis <- read_sav("ILA_Cleaned_Scored_Dataset.sav")
knitr::opts_chunk$set(echo = TRUE)
library(psych)
library(plyr)
library(dplyr)
library(readr)
library(writexl)
library(haven)
library(careless)
library(tidyr)
library(purrr)
library(lubridate)
library(stringr)
ILA_Cleaned_Dataset_Analysis <- read_sav("ILA_Cleaned_Scored_Dataset.sav")
ILA_CorrPlot <- ILA_Cleaned_Dataset_Analysis %>%
select(RME_Mean, Yoni_affect1st, Yoni_affect2nd, Yoni_cog1st, Yoni_cog2nd, Yoni_phys1st, Yoni_phys2nd, MASC_Overall_Correct_Proportion, MASC_Overall_Under_Mentalizing_Proportion, MASC_Overall_Over_Mentalizing_Proportion, MASC_Overall_No_ToM_Proportion, MASC_Emotion_Correct_Proportion, MASC_Emotion_Under_Mentalizing_Proportion, MASC_Emotion_Over_Mentalizing_Proportion, MASC_Emotion_No_ToM_Proportion, MASC_Thoughts_Correct_Proportion, MASC_Thoughts_Under_Mentalizing_Proportion, MASC_Thoughts_Over_Mentalizing_Proportion, MASC_Thoughts_No_ToM_Proportion, MASC_Intentions_Correct_Proportion, MASC_Intentions_Under_Mentalizing_Proportion, MASC_Intentions_Over_Mentalizing_Proportion, MASC_Intentions_No_ToM_Proportion, DP_Ctl_Mean, DA_Ctl_Mean, DP_Exp_Mean, DA_Exp_Mean, Parolini_1_SL_Mean, Parolini_2_SL_Mean, Parolini_2_TL_Mean, SLQ_Altruistic_Calling_Mean, SLQ_Emotional_Healing_Mean, SLQ_Wisdom_Mean, SLQ_Persuasive_Mapping_Mean, SLQ_Org_Stewardship_Mean, SLS_S_Global_Mean, SLS_S_Empowerment_Mean, SLS_S_StB_Mean, SLS_S_Accountability_Mean, SLS_S_Forgiveness_Mean, SLS_S_Courage_Mean, SLS_S_Authenticity_Mean, SLS_S_Humility_Mean, SLS_S_Stewardship_Mean, Leadership_Experience) %>%
cor(use="complete.obs")
RME_SLS_Parolini <- ILA_Cleaned_Dataset_Analysis %>%
select(RME_Mean, SLS_S_Global_Mean, SLS_S_Empowerment_Mean, SLS_S_StB_Mean, SLS_S_Accountability_Mean,  SLS_S_Forgiveness_Mean, SLS_S_Courage_Mean, SLS_S_Authenticity_Mean, SLS_S_Humility_Mean, SLS_S_Stewardship_Mean, Parolini_1_SL_Mean, Parolini_2_SL_Mean, Parolini_2_TL_Mean)
corr_matrix1 <- cor(RME_SLS_Parolini, method = "pearson")
corr_matrix1
ggcorrplot(corr_matrix1, method = 'square',
type = 'lower',
colors = c("red", "white", "blue"))
corr_matrix1 <- cor(RME_SLS_Parolini, method = "pearson", na.rm = T)
corr_matrix1 <- cor(RME_SLS_Parolini, method = "pearson", na.rm = TRUE)
corr_matrix1 <- cor(RME_SLS_Parolini, method = "pearson")
corr_matrix1 <- cor(RME_SLS_Parolini, method = "pearson", use = "complete.obs")
corr_matrix1
#Please run the ILA_Data_Merge_Clean_Script and ILA_Data_Score_Sort_Script to ensure the most updated dataset
library(corrplot)
ggcorrplot(corr_matrix1, method = 'square',
type = 'lower',
colors = c("red", "white", "blue"))
#Please run the ILA_Data_Merge_Clean_Script and ILA_Data_Score_Sort_Script to ensure the most updated dataset
library(ggcorrplot)
#Please run the ILA_Data_Merge_Clean_Script and ILA_Data_Score_Sort_Script to ensure the most updated dataset
install.packages("ggcorrplot")
library(ggcorrplot)
ggcorrplot(corr_matrix1, method = 'square',
type = 'lower',
colors = c("red", "white", "blue"))
YONI_SLS_Parolini <- ILA_Cleaned_Dataset_Analysis %>%
select(Yoni_affect1st, Yoni_affect2nd, Yoni_cog1st, Yoni_cog2nd, Yoni_phys1st, Yoni_phys2nd, SLS_S_Global_Mean, SLS_S_Empowerment_Mean, SLS_S_StB_Mean, SLS_S_Accountability_Mean,  SLS_S_Forgiveness_Mean, SLS_S_Courage_Mean, SLS_S_Authenticity_Mean, SLS_S_Humility_Mean, SLS_S_Stewardship_Mean, Parolini_1_SL_Mean, Parolini_2_SL_Mean, Parolini_2_TL_Mean)
corr_matrix2 <- cor(YONI_SLS_Parolini, method = "pearson", use = "complete.obs")
corr_matrix2
ggcorrplot(corr_matrix2, method = 'square',
type = 'lower',
colors = c("red", "white", "blue"))
YONI_SLS_Parolini <- ILA_Cleaned_Dataset_Analysis %>%
select(Yoni_affect1st, Yoni_affect2nd, Yoni_cog1st, Yoni_cog2nd, Yoni_phys1st, Yoni_phys2nd, SLS_S_Global_Mean, SLS_S_Empowerment_Mean, SLS_S_StB_Mean, SLS_S_Accountability_Mean,  SLS_S_Forgiveness_Mean, SLS_S_Courage_Mean, SLS_S_Authenticity_Mean, SLS_S_Humility_Mean, SLS_S_Stewardship_Mean, Parolini_1_SL_Mean, Parolini_2_SL_Mean, Parolini_2_TL_Mean)
corr_matrix2 <- cor(YONI_SLS_Parolini, method = "pearson", use = "complete.obs")
corr_matrix2
ggcorrplot(corr_matrix2, method = 'square',
type = 'lower',
colors = c("red", "white", "blue"))
MASC_SLS_Parolini <- ILA_Cleaned_Dataset_Analysis %>%
select(MASC_Overall_Correct_Proportion, MASC_Overall_Under_Mentalizing_Proportion, MASC_Overall_Over_Mentalizing_Proportion, MASC_Overall_No_ToM_Proportion, MASC_Emotion_Correct_Proportion, MASC_Emotion_Under_Mentalizing_Proportion, MASC_Emotion_Over_Mentalizing_Proportion, MASC_Emotion_No_ToM_Proportion, MASC_Thoughts_Correct_Proportion, MASC_Thoughts_Under_Mentalizing_Proportion, MASC_Thoughts_Over_Mentalizing_Proportion, MASC_Thoughts_No_ToM_Proportion, MASC_Intentions_Correct_Proportion, MASC_Intentions_Under_Mentalizing_Proportion, MASC_Intentions_Over_Mentalizing_Proportion, MASC_Intentions_No_ToM_Proportion, SLS_S_Global_Mean, SLS_S_Empowerment_Mean, SLS_S_StB_Mean, SLS_S_Accountability_Mean,  SLS_S_Forgiveness_Mean, SLS_S_Courage_Mean, SLS_S_Authenticity_Mean, SLS_S_Humility_Mean, SLS_S_Stewardship_Mean, Parolini_1_SL_Mean, Parolini_2_SL_Mean, Parolini_2_TL_Mean)
corr_matrix3 <- cor(MASC_SLS_Parolini, method = "pearson", use = "complete.obs")
corr_matrix3
ggcorrplot(corr_matrix3, method = 'square',
type = 'lower',
colors = c("red", "white", "blue"))
MASC_SLS_Parolini <- ILA_Cleaned_Dataset_Analysis %>%
select(MASC_Overall_Correct_Proportion, MASC_Overall_Under_Mentalizing_Proportion, MASC_Overall_Over_Mentalizing_Proportion, MASC_Overall_No_ToM_Proportion, MASC_Emotion_Correct_Proportion, MASC_Emotion_Under_Mentalizing_Proportion, MASC_Emotion_Over_Mentalizing_Proportion, MASC_Emotion_No_ToM_Proportion, MASC_Thoughts_Correct_Proportion, MASC_Thoughts_Under_Mentalizing_Proportion, MASC_Thoughts_Over_Mentalizing_Proportion, MASC_Thoughts_No_ToM_Proportion, MASC_Intentions_Correct_Proportion, MASC_Intentions_Under_Mentalizing_Proportion, MASC_Intentions_Over_Mentalizing_Proportion, MASC_Intentions_No_ToM_Proportion, SLS_S_Global_Mean, SLS_S_Empowerment_Mean, SLS_S_StB_Mean, SLS_S_Accountability_Mean,  SLS_S_Forgiveness_Mean, SLS_S_Courage_Mean, SLS_S_Authenticity_Mean, SLS_S_Humility_Mean, SLS_S_Stewardship_Mean, Parolini_1_SL_Mean, Parolini_2_SL_Mean, Parolini_2_TL_Mean)
corr_matrix3 <- cor(MASC_SLS_Parolini, method = "pearson", use = "complete.obs")
corr_matrix3
ggcorrplot(corr_matrix3, method = 'square',
type = 'lower',
colors = c("red", "white", "blue"))
p + theme(text = element_text(size = 8),
axis.text.x = element_text(angle = 90, hjust = 1))
p <- ggcorrplot(corr_matrix3, method = 'square',
type = 'lower',
colors = c("red", "white", "blue"))
p + theme(text = element_text(size = 8),
axis.text.x = element_text(angle = 90, hjust = 1))
p + theme(text = element_text(size = 1),
axis.text.x = element_text(angle = 90, hjust = 1))
p + theme(text = element_text(size = 0.5),
axis.text.x = element_text(angle = 90, hjust = 1))
p + theme(text = element_text(size = 0.5),
axis.text.x = element_text(angle = 45, hjust = 1))
p + theme(text = element_text(size = 0.05),
axis.text.x = element_text(angle = 45, hjust = 1))
p + theme(text = element_text(size = 0.005),
axis.text.x = element_text(angle = 45, hjust = 1))
p + theme(text = element_text(size = 0.000005),
axis.text.x = element_text(angle = 45, hjust = 1))
p + theme(text = element_text(size = 0.000001),
axis.text.x = element_text(angle = 45, hjust = 1))
p + theme(axis.text.x = element_text(size = 1,angle = 45, hjust = 1))
p + theme(axis.text.Y = element_text(size = 8, hjust = 1),
axis.text.x = element_text(size = 1, angle = 45, hjust = 1))
p + theme(axis.text.Y = element_text(size = 8, hjust = 1),
axis.text.x = element_text(size = 1, angle = 45, hjust = 1))
p + theme(axis.text.y = element_text(size = 8, hjust = 1),
axis.text.x = element_text(size = 1, angle = 45, hjust = 1))
p + theme(axis.text.y = element_text(size = 8, hjust = 1),
axis.text.x = element_text(size = 8, angle = 45, hjust = 1))
p + theme(axis.text.y = element_text(size = 8, hjust = 1),
axis.text.x = element_text(size = 8, angle = 90, hjust = 1))
p + theme(axis.text.y = element_text(size = 7, hjust = 1),
axis.text.x = element_text(size = 7, angle = 90, hjust = 1))
getwd()
setwd("/Users/sijanikbal/Documents/Ph.D. in I:O Psychology/Research Labs/Research Lab with Dr. Salter/Images_LinkedIn")
setwd("/Users/sijanikbal/Documents/Ph.D. in I:O Psychology/Research Labs/Research Lab with Dr. Salter/Images_LinkedIn")
df <- read_csv("Data_Clean.csv")
chooseCRANmirror(ind = 1)
install.packages("tidyverse")
install.packages("psych")
install.packages("dplyr")
install.packages("stringr")
install.packages("ggcorrplot")
install.packages("ggplot2")
install.packages("broom")
install.packages("dplyr")
install.packages("multcomp")
install.packages("tidyr")
library(tidyverse)
library(psych)
library(dplyr)
library(stringr)
library(ggcorrplot)
library(tidyr)
library(ggplot2)
library(broom)
library(multcomp)
df <- read_csv("Data_Clean.csv")
df <- df %>%
select(!c(StartDate, EndDate, IPAddress, Status,
RecordedDate, LocationLatitude, LocationLongitude, DistributionChannel,Q1))
df <- read_csv("Data_Clean.csv")
df <- df %>%
tidyverse::select(!c(StartDate, EndDate, IPAddress, Status,
RecordedDate, LocationLatitude, LocationLongitude, DistributionChannel,Q1))
df <- df %>%
dplyr::select(!c(StartDate, EndDate, IPAddress, Status,
RecordedDate, LocationLatitude, LocationLongitude, DistributionChannel,Q1))
chooseCRANmirror(ind = 1)
install.packages("tidyverse")
install.packages("psych")
install.packages("dplyr")
install.packages("stringr")
install.packages("ggcorrplot")
install.packages("ggplot2")
install.packages("dplyr")
install.packages("broom")
install.packages("multcomp")
install.packages("tidyr")
library(tidyverse)
library(psych)
library(dplyr)
library(stringr)
library(ggcorrplot)
library(tidyr)
library(ggplot2)
library(broom)
library(multcomp)
df <- read_csv("Data_Clean.csv")
df <- df %>%
dplyr::select(!c(StartDate, EndDate, IPAddress, Status,
RecordedDate, LocationLatitude, LocationLongitude, DistributionChannel,Q1))
df <- df %>% slice(-2)
asian_man_df <- df %>%
dplyr::select(ResponseId, Column1, `Duration (in seconds)`, Progress, UserLanguage, Finished, Attention_check, starts_with("Asian_Man"), starts_with("Demographics"))
asian_man_df <- asian_man_df %>%
filter(Asian_Man_1 != "N/A")
colnames(asian_man_df) <- asian_man_df[1,]
asian_man_df <- asian_man_df[-1, ]
colnames(asian_man_df)[7] = "Attention_check"
asian_woman_df <- df %>%
dplyr::select(ResponseId, Column1, `Duration (in seconds)`, Progress, UserLanguage, Finished, Attention_check, starts_with("Asian_Woman"), starts_with("Demographics"))
asian_woman_df <- asian_woman_df %>%
filter(Asian_Woman_1 != "N/A")
colnames(asian_woman_df) <- asian_woman_df[1,]
asian_woman_df <- asian_woman_df[-1, ]
colnames(asian_woman_df)[7] = "Attention_check"
black_man_df <- df %>%
dplyr::select(ResponseId, Column1, `Duration (in seconds)`, Progress, UserLanguage, Finished, Attention_check, starts_with("Black_Man"), starts_with("Demographics"))
black_man_df <- black_man_df %>%
filter(Black_Man_1 != "N/A")
colnames(black_man_df) <- black_man_df[1,]
black_man_df <- black_man_df[-1, ]
colnames(black_man_df)[7] = "Attention_check"
black_woman_df <- df %>%
dplyr::select(ResponseId, Column1, `Duration (in seconds)`, Progress, UserLanguage, Finished, Attention_check, starts_with("Black_Woman"), starts_with("Demographics"))
black_woman_df <- black_woman_df %>%
filter(Black_Woman_1 != "N/A")
colnames(black_woman_df) <- black_woman_df[1,]
black_woman_df <- black_woman_df[-1, ]
colnames(black_woman_df)[7] = "Attention_check"
blight_man_df <- df %>%
dplyr::select(ResponseId, Column1, `Duration (in seconds)`, Progress, UserLanguage, Finished, Attention_check, starts_with("Blight_Man"), starts_with("Demographics"))
blight_man_df <- blight_man_df %>%
filter(Blight_Man_1 != "N/A")
colnames(blight_man_df) <- blight_man_df[1,]
blight_man_df <- blight_man_df[-1, ]
colnames(blight_man_df)[7] = "Attention_check"
blight_woman_df <- df %>%
dplyr::select(ResponseId, Column1, `Duration (in seconds)`, Progress, UserLanguage, Finished, Attention_check, starts_with("Blight_Woman"), starts_with("Demographics"))
blight_woman_df <- blight_woman_df %>%
filter(Blight_Woman_1 != "N/A")
colnames(blight_woman_df) <- blight_woman_df[1,]
blight_woman_df <- blight_woman_df[-1, ]
colnames(blight_woman_df)[7] = "Attention_check"
wasian_man_df <- df %>%
dplyr::select(ResponseId, Column1, `Duration (in seconds)`, Progress, UserLanguage, Finished, Attention_check, starts_with("Wasian_Man"), starts_with("Demographics"))
wasian_man_df <- wasian_man_df %>%
filter(Wasian_Man_1 != "N/A")
colnames(wasian_man_df) <- wasian_man_df[1,]
wasian_man_df <- wasian_man_df[-1, ]
colnames(wasian_man_df)[7] = "Attention_check"
wasian_woman_df <- df %>%
dplyr::select(ResponseId, Column1, `Duration (in seconds)`, Progress, UserLanguage, Finished, Attention_check, starts_with("Wasian_Woman"), starts_with("Demographics"))
wasian_woman_df <- wasian_woman_df %>%
filter(Wasian_Woman_1 != "N/A")
colnames(wasian_woman_df) <- wasian_woman_df[1,]
wasian_woman_df <- wasian_woman_df[-1, ]
colnames(wasian_woman_df)[7] = "Attention_check"
white_man_df <- df %>%
dplyr::select(ResponseId, Column1, `Duration (in seconds)`, Progress, UserLanguage, Finished, Attention_check, starts_with("White_Man"), starts_with("Demographics"))
white_man_df <- white_man_df %>%
filter(White_Man_1 != "N/A")
colnames(white_man_df) <- white_man_df[1,]
white_man_df <- white_man_df[-1, ]
colnames(white_man_df)[7] = "Attention_check"
white_woman_df <- df %>%
dplyr::select(ResponseId, Column1, `Duration (in seconds)`, Progress, UserLanguage, Finished, Attention_check, starts_with("White_Woman"), starts_with("Demographics"))
white_woman_df <- white_woman_df %>%
filter(White_Woman_1 != "N/A")
colnames(white_woman_df) <- white_woman_df[1,]
white_woman_df <- white_woman_df[-1, ]
colnames(white_woman_df)[7] = "Attention_check"
new_df <- rbind(asian_man_df, asian_woman_df,
black_man_df, black_woman_df,
blight_man_df, blight_woman_df,
wasian_man_df, wasian_woman_df,
white_man_df, white_woman_df)
new_df = new_df[,!(names(new_df) %in% c("Timing - First Click","Timing - Last Click"))]
colnames(new_df)[8] <- "timing_page_submit_LP"
colnames(new_df)[9] <- "click_count_LP"
colnames(new_df)[10] <- "item1_leader"
colnames(new_df)[11] <- "timing_leader"
colnames(new_df)[12] <- "click_count_leader"
colnames(new_df)[13] <- "item2_independent"
colnames(new_df)[14] <- "timing_independent"
colnames(new_df)[15] <- "click_count_independent"
colnames(new_df)[16] <- "item3_ambitious"
colnames(new_df)[17] <- "timing_ambitious"
colnames(new_df)[18] <- "click_count_ambitious"
colnames(new_df)[19] <- "item4_loyal"
colnames(new_df)[20] <- "timing_loyal"
colnames(new_df)[21] <- "click_count_loyal"
colnames(new_df)[22] <- "item5_sensitive"
colnames(new_df)[23] <- "timing_sensitive"
colnames(new_df)[24] <- "click_count_sensitive"
colnames(new_df)[25] <- "item6_warm"
colnames(new_df)[26] <- "timing_warm"
colnames(new_df)[27] <- "click_count_warm"
colnames(new_df)[28] <- "item7_compassionate"
colnames(new_df)[29] <- "timing_compassionate"
colnames(new_df)[30] <- "click_count_compassionate"
colnames(new_df)[31] <- "item8_adaptable"
colnames(new_df)[32] <- "timing_adaptable"
colnames(new_df)[33] <- "click_count_adaptable"
colnames(new_df)[34] <- "item9_sincere"
colnames(new_df)[35] <- "timing_sincere"
colnames(new_df)[36] <- "click_count_sincere"
colnames(new_df)[37] <- "item10_reliable"
colnames(new_df)[38] <- "timing_reliable"
colnames(new_df)[39] <- "click_count_reliable"
colnames(new_df)[40] <- "item11_truthful"
colnames(new_df)[41] <- "timing_truthful"
colnames(new_df)[42] <- "click_count_truthful"
colnames(new_df)[43] <- "item12_race"
colnames(new_df)[44] <- "timing_race"
colnames(new_df)[45] <- "click_count_race"
colnames(new_df)[46] <- "dem1_age"
colnames(new_df)[47] <- "dem2_gender"
colnames(new_df)[48] <- "dem3_ethnicity"
colnames(new_df)[49] <- "dem3_ethnicity_other"
colnames(new_df)[50] <- "dem4_employment_status"
colnames(new_df)[51] <- "dem5_occupation"
new_df <- new_df %>%
filter(Finished == TRUE & Attention_check == "Digital Marketing Role")
fac_var <- c("Group", "item12_race", "dem2_gender", "dem3_ethnicity", "dem4_employment_status")
new_df <- new_df %>%
mutate(across(fac_var, as.factor))
num_var <- c("Duration (in seconds)", "timing_page_submit_LP", "click_count_LP","item1_leader", "timing_leader", "click_count_leader", "item2_independent", "timing_independent", "click_count_independent", "item3_ambitious", "timing_ambitious", "click_count_ambitious", "item4_loyal", "timing_loyal", "click_count_loyal", "item5_sensitive", "timing_sensitive", "click_count_sensitive", "item6_warm", "timing_warm", "click_count_warm", "item7_compassionate", "timing_compassionate", "click_count_compassionate", "item8_adaptable", "timing_adaptable", "click_count_adaptable", "item9_sincere", "timing_sincere", "click_count_sincere", "item10_reliable", "timing_reliable", "click_count_reliable", "item11_truthful", "timing_truthful", "click_count_truthful", "timing_race", "click_count_race", "dem1_age")
new_df <- new_df %>%
mutate(across(num_var, as.numeric))
new_df <- new_df %>%
mutate(masculinity = (item1_leader + item2_independent + item3_ambitious) / 3,
femininity = (item4_loyal + item5_sensitive + item6_warm + item7_compassionate) / 4,
neutral = (item8_adaptable + item9_sincere + item10_reliable + item11_truthful) / 4)
aggregated_scale <- new_df[ , c("masculinity", "femininity", "neutral")]
alpha(aggregated_scale)
## all the aggregated scales highly correlate with the overall scale (highest corr neutral = 0.93)
## so dropping neutral would have the most impact on alpha value, while dropping masculinity or feminity scale would still result in a fair alpha value (alpha >.8)
new_df <- new_df %>%
mutate(total_response_time = timing_leader + timing_independent + timing_ambitious +
timing_loyal + timing_sensitive + timing_warm + timing_compassionate +
timing_adaptable + timing_sincere + timing_reliable + timing_truthful)
alpha(aggregated_scale)
install.packages("apaTables")
library(apaTables)
View(aggregated_scale)
corr_agg <- cor(aggregated_scale, method = "pearson")
corr_agg <- cor(aggregated_scale, method = "pearson", use = "complete.obs")
corr_agg
apa.cor.table(aggregated_scale,
filename = "correlation_table.doc",
table.number = 1)
apa.cor.table(aggregated_scale,
filename = "correlation_table.doc",
table.number = 1,
check.alpha = TRUE)
cronbach_alpha <- alpha(aggregated_scale)$total$raw_alpha
cronbach_alpha
cronbach_alpha <- alpha(aggregated_scale)$raw_alpha
cronbach_alpha
apa.cor.table(aggregated_scale,
filename = "correlation_table_2.doc",
table.number = 1)
